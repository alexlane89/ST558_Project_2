---
title: "ST558 Project 2"
author: "Charles Lane"
format: html
editor: visual
---

## Introduction

>  In searching for an interesting, data set with which to build a query app, several free data sources were evaluated, primarily through the admittedly subjective lens of "do I find this interesting?" The question is, what data do I find interesting, and why? Such that I might communicate to my audience why it's interesting and hopefully share some of that enjoyment. /
>  The first attribute I look for instinctually is data with a tie to historical events, people, geography, etc. The most comfortable items in that category are generally census population or business data, especially for North Carolina. I've lived in North Carolina my entire life, and I certainly enjoy exploring more of it. However, as I was reading through several API options, I stumbled across a data set that may not have checked the very familiar/local box, but certainly intrigued my desire to see history. /
>  All historical Nobel Prizes, and their associated laureates are included in a data set offered by the Nobel Prize committee. This data set is quite intriguing to me because of its historical connotations, certainly over the past 1 and a quarter century, but also what I might call its "succinct breadth" of topics. There are only 6 categories of Nobel Prizes given each year, but what a wonderful snapshot of time is available by reviewing recognitions in Chemistry, Physics, Medicine, Economics, Literature, and of course Peace across years?

## Querying the API

### Nobel Prize Information

> My first step is to attempt to query the Nobel API statically. Before I build the app, I'd like to make sure I can get a variety of different information and work with it realistically, before creating a shiny app which will allow others to query the same data sets. /
>  There are several packages I would initially like to load given the activities I am attempting. To be able to make an API call and work with the resulting data, I will load 'httr' and 'jsonlite' packages.

```{r}
library(tidyverse)
library(httr)
library(jsonlite)
```

> There are 2 specificic endpoints for the Nobel Prize dataset: 'Laureates' and 'Nobel Prizes'. More information on this data can be found through the Nobel Prize organization, here: \
https://app.swaggerhub.com/apis/NobelMedia/NobelMasterData/2.1 \
> For our purposes, we will allow the following 6 dataset options to be selectable from the 2 endpoints above: \

**1)**    Chemistry Nobel Prizes
**2)**    Physiology & Medicine Prizes
**3)**    Peace Prizes
**4)**    Physics Prizes
**5)**    Literature Prizes
**6)**    Economics Prizes
**7)**    Laureate Information

> Eventually, we'll create one function to retrieve a data table for all years of each Nobel Prize category. The first "sub-function" will be simply one to query the Nobel API with a specification for each category. A list will be returned that includes elements associated with each "bucket" of 25-year prize data.

**NOTE** - The API call limits results to 25 rows (one year per row), so to create a result with all years since 1901, multiple queries must be made for each 25-year "bucket", then combined.

```{r}
get_data <- function(category = "Chemistry") {
  if (category == "Chemistry") {
    q_code <- "che"
  } else if (category == "Economics") {
    q_code <- "eco"
  } else if (category == "Literature") {
    q_code <- "lit"
  } else if (category == "Peace") {
    q_code <- "pea"
  } else if (category == "Physics") {
    q_code <- "phy"
  } else if (category == "Medicine") {
    q_code <- "med"
  } else {
    stop("category argument must be an acceptable prize option")
  }
  num_q <- ((getRmetricsOptions("currentYear")[[1]] - 1901) %/% 25) + 1
  year_start <- 1901
  year_end <- getRmetricsOptions("currentYear")[[1]]
  x_a <- GET(paste0("http://api.nobelprize.org/2.1/nobelPrizes?nobelPrizeYear=1901&yearTo=1925&nobelPrizeCategory=",q_code))
  x_b <- GET(paste0("http://api.nobelprize.org/2.1/nobelPrizes?nobelPrizeYear=1926&yearTo=1950&nobelPrizeCategory=",q_code))
  x_c <- GET(paste0("http://api.nobelprize.org/2.1/nobelPrizes?nobelPrizeYear=1951&yearTo=1975&nobelPrizeCategory=",q_code))
  x_d <- GET(paste0("http://api.nobelprize.org/2.1/nobelPrizes?nobelPrizeYear=1976&yearTo=2000&nobelPrizeCategory=",q_code))
  if (num_q == 5) {
    x_e <- GET(paste0("http://api.nobelprize.org/2.1/nobelPrizes?nobelPrizeYear=2000&yearTo=",getRmetricsOptions("currentYear")[[1]],"&nobelPrizeCategory=",q_code))
    x_f <- NULL
  } else if (num_q == 6) {
    x_e <- GET(paste0("http://api.nobelprize.org/2.1/nobelPrizes?nobelPrizeYear=2001&yearTo=2025&nobelPrizeCategory=",q_code))
    x_f <- GET(paste0("http://api.nobelprize.org/2.1/nobelPrizes?nobelPrizeYear=2026&yearTo=",getRmetricsOptions("currentYear")[[1]],"&nobelPrizeCategory=",q_code))
  }
  return(list(x_a, x_b, x_c, x_d, x_e, x_f))
}
```

> After the raw JSON data has been called from the Nobel Prize API, a 'tibble_data' function will complete the next small step; to extract from JSON and create tibbles for each 25-year bucket.

```{r}
tibble_data <- function(x) {
  y_a <- fromJSON(rawToChar(x[[1]]$content))
  y_b <- fromJSON(rawToChar(x[[2]]$content))
  y_c <- fromJSON(rawToChar(x[[3]]$content))
  y_d <- fromJSON(rawToChar(x[[4]]$content))
  y_e <- fromJSON(rawToChar(x[[5]]$content))
  y_f <- NULL
  if (!is.null(x[[6]])) {
    y_f <- fromJSON(rawToChar(x[[6]]$content))
  }
  z_a <- as_tibble(y_a$nobelPrizes)
  z_b <- as_tibble(y_b$nobelPrizes)
  z_c <- as_tibble(y_c$nobelPrizes)
  z_d <- as_tibble(y_d$nobelPrizes)
  z_e <- as_tibble(y_e$nobelPrizes)
  z_f <- NULL
  if (!is.null(y_f)) {
    z_f <- as_tibble(y_f$nobelPrizes)
  }
  return(list(z_a, z_b, z_c, z_d, z_e, z_f))
}
```

> The final small step necessary is to merge the 25-year bucket elements into one combined table. This will be completed via a 'merge_data' function.

```{r}
merge_data <- function(x) {
  dplyr::bind_rows(x[[1]], x[[2]], x[[3]], x[[4]], x[[5]], x[[6]])
}
```


> The resulting list of 10 elements included mostly elements describing attributes of the query itself. i.e. headers about what type of server hosts the data, how the content is encoded, which cookies are included in the request, the date/time of the request, etc. I was able to find that the information in question, however, appeared to be in the $content list element. Within this element, several more data frames existed. For example, the category and the laureate names, amongst other information.

> A 'clean_data' function will look at the $content element and also create a new variable/column to show the Adjusted prize amounts in current USD currency. The prize is based in Sweden, so the initial Prize amounts are listed in Swedish Kroner. This function includes an argument to define which conversion rate is preferred.


```{r}
clean_data <- function(x, conv = "USD/SEK") {
  conversion <- c(0.095, 1/0.095)
  names(conversion) <- c("USD/SEK", "SEK/USD")

  c_data <- x |>
    select(awardYear, dateAwarded, laureates) |>
    mutate(Category = x$category$en,
           AdjustedPrize_SEK = x$prizeAmountAdjusted,
           AdjustedPrize_USD = x$prizeAmountAdjusted * conversion[1]
           ) |>
    unnest(cols = laureates) |>
    select(!links)

  return(c_data)
}
```

> Create a wrapper function to get the data, convert to tibble, combine all years into one dataset, and finally, clean the dataset.

```{r}
get_Nobel_Prize_data <- function(category = "Chemistry") {
  data_list <- get_data(category = category)
  tibble_list <- tibble_data(data_list)
  merged_data <- merge_data(tibble_list)
  cleaned <- clean_data(merged_data)
  return(cleaned)
}
```


> Test out the functions

```{r}
physics_prizes <- get_Nobel_Prize_data(category = "Physics")
```

### Laureate Endpoint

> To see attributes of the Nobel laureates, another API endpoint "laureates" will be referenced. This endpoint returns birth country, institution information about the laureates. It also includes laureate id references which are in the Nobel Prize endpoints as well.

```{r}
  x <- GET("https://api.nobelprize.org/2.1/laureates")
  y <- content(x, "text") |>
    fromJSON()
  z <- as_tibble(y$laureates)
```

> There is a limit to how many laureates can be returned by any one requesst - 25. To iterate through buckets of 25 laureates at a time, I first need to determine the max number of laureate ids. the 'det_last_id' function determines if data is returned for a specific ID from the query. The function returns a TRUE or FALSE based on if the output query has contents or not.

```{r}
det_id_res <- function(ID = 1100) {
  ID_STR <- as.character(ID)
  a <- GET(paste0("https://api.nobelprize.org/2.1/laureates?ID=",
                  ID_STR))
  b <- content(a, "text") |>
    fromJSON()

return(is_empty(b$laureates))
}
```

> I can use another function to iterate through and determine the last ID.

```{r}
det_last_id <- function(begin = 1000, end = 1050) {
  for (i in seq(from = begin, to = end)) {
    if (det_id_res(ID = i) == TRUE) {
      return(paste0("Max ID = ",i))
      stop()
    }
  }
}

det_last_id()
```

> Now I'll need to create a dataset for all 1010 ID entries.

```{r}

get_laureate_data <- function() {
  a <- GET(paste0("https://api.nobelprize.org/2.1/laureates"))
  b <- content(a, "text") |>
    fromJSON()
  c <- as_tibble(b$laureates)
  d <- c
  for (i in seq(from = 26, to = 1010, by = 25)) {
    a <- GET(paste0("https://api.nobelprize.org/2.1/laureates?offset=",
                    i))
    b <- content(a, "text") |>
      fromJSON()
    c <- as_tibble(b$laureates)
    d <- bind_rows(d, c)
  }
  return(d)
}
```

> Test this function, and a note that this should only be run sporadically as it makes a large amount of API calls. Also, for this reason, any cleaning functions should be separate, and I'm not going to create one request & cleaning function like I did for the Nobel Prize data.

```{r}
laureate_resp <- get_laureate_data()
```

> Removing some extraneous rows to clean the data:

```{r}
clean_name_laureate <- function(x) {
  y <- x |>
    unnest(cols = c(knownName)) |>
    mutate(Known_Name = en) |>
    select(!en & !se & !no & !familyName & !fullName & !givenName &
             !fileName & !wikipedia & !sameAs & !links & !wikidata
           & !founded & !foundedCountry & !foundedContinent
           & !foundedCountryNow)
  return(y)
}
```

> There are SO many attributes associated with 'birth', including city then & currently in multiple languages, country, and continent then and currently in each language. Let's isolate just the english descriptions of city, country, and continent then (not the current geographical locations).

```{r}
clean_birth_laureate <- function(x) {
  y <- x |>
    unnest(cols = birth) |>
    mutate(Birth_Date = date) |>
    select(!date) |>
    unnest(cols = place) |>
    select(!locationString) |>
    unnest(cols = city) |>
    mutate(Birth_City = en) |>
    select(!en & !se & !no & !cityNow & !countryNow) |>
    unnest(cols = country) |>
    mutate(Birth_Country = en) |>
    select(!en & !se & !no) |>
    unnest(cols = continent) |>
    mutate(Birth_Continent = en) |>
    select(!en & !se & !no)
}
```

> Similar to birth, there are an equal number of 'death' attributes. A similar function can be written to clean up the 'death' atributes.

```{r}
clean_death_laureate <- function(x) {
  y <- x |>
    unnest(cols = death) |>
    mutate(Death_Date = date) |>
    select(!date) |>
    unnest(cols = place) |>
    unnest(cols = city) |>
    mutate(Death_City = en) |>
    select(!en & !se & !no & !cityNow & !countryNow) |>
    unnest(cols = country) |>
    mutate(Death_Country = en) |>
    select(!en & !se & !no) |>
    unnest(cols = continent) |>
    mutate(Death_Continent = en) |>
    select(!en & !se & !no & !locationString & !sameAs)
}
```

> Final cleaning stage to parse out the organiation name and unnest the nobelPrizes variable.

```{r}
clean_addl_laureate <- function(x) {
  y <- x |>
    unnest(cols = nobelPrizes) |>
    unnest(cols = category) |>
    mutate(Category = en) |>
    select(!en & !se & !no & !categoryFullName) |>
    unnest(cols = motivation) |>
    mutate(Motivation = en) |>
    select(!en & !se & !no) |>
    unnest(cols = orgName) |>
    mutate(Organization = en) |>
    select(!en & !se & !no)
  return(y)
}
```



> Use all the individual cleaning functions to ultimately clean the laureate data:

```{r}
clean_laureate <- function(x) {
  y <- clean_name_laureate(x) |>
    clean_birth_laureate() |>
    clean_death_laureate() |>
    clean_addl_laureate()
  return(y)
}
```


## Data Visualization

> There are a variety of different visuals which can be developed from the preceding Nobel Prize data.

```{r}
z <- clean_laureate(laureate_resp)
```

> Plot a bar graph with counts of Nobel Prizes associated with each Birth Country

```{r}
gg <- ggplot(z, aes(Birth_Country))
gg + geom_bar()
```

> Create a contingency table of prize years and adjusted prize values

```{r}
con1 <- table(physics_prizes$awardYear, physics_prizes$AdjustedPrize_USD)

con1
```

